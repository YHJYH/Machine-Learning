supervised learning<br>
unsupervised learning<br>
clustering<br>
<br>
<b>linear regression</b><br>
hypothesis<br>
training set<br>
<br>
<b>cost function</b><br>
parameter<br>
modelling error<br>
Goal: find parameters that minimize cost function <em>J</em>: need an algorithm<br>
<br>
<b>gradient descent algorithm</b><br>
can: local minimum<br>
cannot: global minimum<br>
<blockquote>思考：能否在找到local min之后取一个平面，根据平面和function在其他位置的交点来寻找其他的local min，从而确定global min</blockquote>
赋值assignment<q>:=</q><br>
assertion<q>=</q><br>
batch gradient descent algorithm: sum over m training examples<br>
learning rate<br>
importance of simultaneity<br>
<br>
gradient descent for linear regression<br>
convex function<br>
normal equations<br>
<br>
dimension of matrix = number of rows * number of columns<br>
not commutative<br>
is associative<br>
inverse and transpose<br>
transpose in matlab: x=y'<br>
