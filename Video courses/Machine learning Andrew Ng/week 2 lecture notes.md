multiple features<br>
gradient descent on multiple variables<br>
<br>
features scaling: make sure features are on a smiliar scale<br>
method: x_n = (x_n - miu_n)/s_n <b>mean normalization</b>: make features have approximately zero mean<br>
miu_n = average , s_n = standardized error<br>
<br>
test the gradient descent: <b>min<i>J</i> converges</b><br>
plot cost function <i>J</i> against number of iterations (a converging curve)<br>
if learning rate is <b>too small</b>: slow convergence<br>
if learning rate is <b>too large</b>: no convergence<br>
